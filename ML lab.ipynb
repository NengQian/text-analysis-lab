{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/file_utils.py\n",
    "%run src/configuration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_test = ['BMW-AnnualReport-2016.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_documents = ['BMW-AnnualReport-2016.json', 'CarlZeissMeditec-AnnualReport-2016.json', 'BVB-AnnualReport-2016.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ['BMW-AnnualReport-2015.json', 'BMW-AnnualReport-2016.json', 'BMW-AnnualReport-2017.json', \n",
    " 'CarlZeissMeditec-AnnualReport-2015.json', 'CarlZeissMeditec-AnnualReport-2016.json', 'CarlZeissMeditec-AnnualReport-2017.json',\n",
    " 'BVB-AnnualReport-2015.json', 'BVB-AnnualReport-2016.json', 'BVB-AnnualReport-2017.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'type'\n",
    "PARAGRAPH = 'paragraph'\n",
    "CONTENT = 'content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readContentOfFile(file_name):\n",
    "    content = ''\n",
    "    try:\n",
    "        with open(file_name) as f:\n",
    "            data = json.load(f)\n",
    "            for item in data:\n",
    "                typeDoc = item[TYPE]\n",
    "                if typeDoc == PARAGRAPH:\n",
    "                    content += item[CONTENT]\n",
    "    except:\n",
    "        FileUtils.fix_json(file_name)\n",
    "        with open(file_name) as f:\n",
    "            data = json.load(f)\n",
    "            for item in data:\n",
    "                typeDoc = item[TYPE]\n",
    "                if typeDoc == PARAGRAPH:\n",
    "                    content += item[CONTENT]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocabularly = set()\n",
    "for document in documents:\n",
    "    content_of_document = readContentOfFile(FILE_PATH + document)\n",
    "    nlp = spacy.load(\"de\")\n",
    "    sentence = nlp(content_of_document)\n",
    "    filtered_words = [word for word in sentence if word.lower_ not in STOP_WORDS]\n",
    "    filtered_words_withoutdigits = [word for word in filtered_words if not word.is_digit]\n",
    "    filtered_words_withoutpunc = [word for word in filtered_words_withoutdigits if word.pos_ != 'PUNCT']\n",
    "    vocabularly = set()\n",
    "    for word in filtered_words_withoutpunc:\n",
    "        vocabularly.add(word.text.replace('\\n', '').strip().lower())\n",
    "    new_vocab = set()\n",
    "    for u in vocabularly:\n",
    "        if u != '':\n",
    "            new_vocab.add(u)\n",
    "    vectorizer = TfidfVectorizer(vocabulary=new_vocab)\n",
    "    tfidf_matrix = vectorizer.fit_transform([content_of_document])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    corpus_index = [n for n in ['Values']]\n",
    "    df = pd.DataFrame(tfidf_matrix.T.todense(), index=feature_names, columns=corpus_index)\n",
    "    df = df.sort_values(by=['Values'], ascending=False)\n",
    "    common_vocabularly.update(df.head(1000).index.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=common_vocabularly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(\n",
    "    [readContentOfFile(FILE_PATH + 'BVB-AnnualReport-2011.json'), \n",
    "     readContentOfFile(FILE_PATH + 'BVB-AnnualReport-2012.json'), \n",
    "     readContentOfFile(FILE_PATH + 'BMW-AnnualReport-2012.json'),\n",
    "     readContentOfFile(FILE_PATH + 'BMW-AnnualReport-2011.json'),\n",
    "     readContentOfFile(FILE_PATH + 'CarlZeissMeditec-AnnualReport-2013.json'),\n",
    "     readContentOfFile(FILE_PATH + 'CarlZeissMeditec-AnnualReport-2012.json'),\n",
    "     readContentOfFile(FILE_PATH + 'BVB-AnnualReport-2013.json'), \n",
    "     readContentOfFile(FILE_PATH + 'BMW-AnnualReport-2013.json'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 0, 0, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, init='k-means++')\n",
    "km.fit(tfidf_matrix)\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lemmatization(document):\n",
    "    content_of_document = readContentOfFile(document)\n",
    "    nlp = spacy.load(\"de\")\n",
    "    sentence = nlp(content_of_document)\n",
    "    filtered_words = [word for word in sentence if word.lower_ not in STOP_WORDS]\n",
    "    filtered_words_withoutdigits = [word for word in filtered_words if not word.is_digit]\n",
    "    filtered_words_withoutpunc = [word for word in filtered_words_withoutdigits if word.pos_ != 'PUNCT']\n",
    "    filtered_lemmas = [word.lemma_ for word in filtered_words_withoutpunc]\n",
    "    lemmatized_content = \" \".join(item for item in filtered_lemmas)\n",
    "    return lemmatized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocabularly_lem = set()\n",
    "for document in documents:\n",
    "    content_of_document = readContentOfFile(FILE_PATH + document)\n",
    "    nlp = spacy.load(\"de\")\n",
    "    sentence = nlp(content_of_document)\n",
    "    filtered_words = [word for word in sentence if word.lower_ not in STOP_WORDS]\n",
    "    filtered_words_withoutdigits = [word for word in filtered_words if not word.is_digit]\n",
    "    filtered_words_withoutpunc = [word for word in filtered_words_withoutdigits if word.pos_ != 'PUNCT']\n",
    "    filtered_lemmas = [word.lemma_ for word in filtered_words_withoutpunc]\n",
    "    vocabularly = set()\n",
    "    for word in filtered_lemmas:\n",
    "        vocabularly.add(word.replace('\\n', '').strip().lower())\n",
    "    new_vocab = set()\n",
    "    for u in vocabularly:\n",
    "        if u != '':\n",
    "            new_vocab.add(u)\n",
    "\n",
    "    lemmatized_content = \" \".join(item for item in filtered_lemmas)\n",
    "    vectorizer = TfidfVectorizer(vocabulary=new_vocab)\n",
    "    tfidf_matrix = vectorizer.fit_transform([lemmatized_content])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    corpus_index = [n for n in ['Values']]\n",
    "    df = pd.DataFrame(tfidf_matrix.T.todense(), index=feature_names, columns=corpus_index)\n",
    "    df = df.sort_values(by=['Values'], ascending=False)\n",
    "    common_vocabularly_lem.update(df.head(1000).index.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=common_vocabularly_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(\n",
    "    [perform_lemmatization(FILE_PATH + 'BVB-AnnualReport-2011.json'), \n",
    "     perform_lemmatization(FILE_PATH + 'BVB-AnnualReport-2012.json'), \n",
    "     perform_lemmatization(FILE_PATH + 'BMW-AnnualReport-2012.json'),\n",
    "     perform_lemmatization(FILE_PATH + 'BMW-AnnualReport-2011.json'),\n",
    "     perform_lemmatization(FILE_PATH + 'CarlZeissMeditec-AnnualReport-2013.json'),\n",
    "     perform_lemmatization(FILE_PATH + 'CarlZeissMeditec-AnnualReport-2012.json'),\n",
    "     perform_lemmatization(FILE_PATH + 'BVB-AnnualReport-2013.json'), \n",
    "     perform_lemmatization(FILE_PATH + 'BMW-AnnualReport-2013.json'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2, 2, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, init='k-means++')\n",
    "km.fit(tfidf_matrix)\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>0.655367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>0.372566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>0.252614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unternehmen</th>\n",
       "      <td>0.123924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment</th>\n",
       "      <td>0.108831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risiko</th>\n",
       "      <td>0.108831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitglied</th>\n",
       "      <td>0.094532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>höhe</th>\n",
       "      <td>0.093737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fahrzeug</th>\n",
       "      <td>0.087382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vorstehen</th>\n",
       "      <td>0.086588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Values\n",
       "bmw          0.655367\n",
       "group        0.372566\n",
       "million      0.252614\n",
       "unternehmen  0.123924\n",
       "segment      0.108831\n",
       "risiko       0.108831\n",
       "mitglied     0.094532\n",
       "höhe         0.093737\n",
       "fahrzeug     0.087382\n",
       "vorstehen    0.086588"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de\")\n",
    "sentence = nlp(content_of_all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_words = [word for word in sentence if word.lower_ not in STOP_WORDS]\n",
    "filtered_words_withoutpunc = [word for word in filtered_words if word.pos_ != 'PUNCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabularly = []\n",
    "for word in filtered_words_withoutpunc:\n",
    "    vocabularly.append(word.text.replace('\\n', '').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_vocab = set()\n",
    "for u in vocabularly:\n",
    "    if u != '':\n",
    "        new_vocab.add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform([readContentOfFile(FILE_PATH + 'BVB-AnnualReport-2016.json'), readContentOfFile(FILE_PATH + 'BMW-AnnualReport-2016.json')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14420\n"
     ]
    }
   ],
   "source": [
    "print (len(new_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in ['A', 'B']]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tfidf_matrix.T.todense(), index=feature_names, columns=corpus_index)\n",
    "#df['1'].argmax()\n",
    "# print(df.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dortmund\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print (df['A'].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               A         B\n",
      "bmw                     0.000000  0.778350\n",
      "group                   0.000871  0.314828\n",
      "2016                    0.160191  0.173860\n",
      "2015                    0.147132  0.169833\n",
      "automobile              0.000000  0.083967\n",
      "unternehmen             0.040048  0.079211\n",
      "höhe                    0.079225  0.079211\n",
      "risiken                 0.060072  0.078539\n",
      "vorstand                0.001741  0.073169\n",
      "vorstands               0.000871  0.071826\n",
      "aufsichtsrat            0.053107  0.066456\n",
      "segment                 0.002612  0.062429\n",
      "vorjahr                 0.084449  0.061086\n",
      "geschäftsjahr           0.075743  0.061086\n",
      "aufsichtsrats           0.010447  0.053702\n",
      "beziehungsweise         0.000000  0.051890\n",
      "entwicklung             0.017412  0.051017\n",
      "fahrzeuge               0.000000  0.050947\n",
      "mini                    0.000000  0.050947\n",
      "wesentlichen            0.047883  0.050346\n",
      "compliance              0.001741  0.049674\n",
      "2017                    0.023506  0.047661\n",
      "rahmen                  0.025248  0.047661\n",
      "insbesondere            0.036565  0.046318\n",
      "mitarbeiter             0.011318  0.043633\n",
      "mitglieder              0.010447  0.042290\n",
      "31                      0.012188  0.041619\n",
      "chancen                 0.014800  0.041619\n",
      "hinaus                  0.019153  0.041619\n",
      "finanzdienstleistungen  0.000000  0.041512\n",
      "...                          ...       ...\n",
      "halbfinalsieg           0.001224  0.000000\n",
      "handelsgesetzbuches     0.002447  0.000000\n",
      "handelsaufnahme         0.001224  0.000000\n",
      "handelsauf-             0.000000  0.000000\n",
      "handels-                0.000000  0.000000\n",
      "handelns                0.004894  0.000000\n",
      "handelbar               0.001224  0.000000\n",
      "han-                    0.000000  0.000000\n",
      "hamburg                 0.002447  0.000000\n",
      "haltung                 0.001224  0.000000\n",
      "haltenen                0.002447  0.000000\n",
      "hallesche               0.003671  0.000000\n",
      "halbjahresfi-           0.000000  0.000000\n",
      "halbjahres-             0.000000  0.000000\n",
      "halb                    0.001224  0.000000\n",
      "gülti-gen               0.000000  0.000000\n",
      "haftet                  0.001224  0.000000\n",
      "haftenden               0.024472  0.000000\n",
      "haftende                0.024472  0.000000\n",
      "haf-                    0.000000  0.000000\n",
      "haf                     0.003671  0.000000\n",
      "habilitationszentrum    0.001224  0.000000\n",
      "ha-                     0.000000  0.000000\n",
      "h.                      0.000000  0.000000\n",
      "h                       0.000000  0.000000\n",
      "gütungsbestandteile     0.001224  0.000000\n",
      "gündogan                0.009789  0.000000\n",
      "gün-                    0.000000  0.000000\n",
      "gültige                 0.001224  0.000000\n",
      "€                       0.000000  0.000000\n",
      "\n",
      "[14420 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df.sort_values(by=['B'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
